{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supernova Example: BOLFI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we use BOLFI by Gutmann et al. (2016) as a method of estimating cosmological parameters from supernovae data.  The following model describes the distance modulus as a function of redshift:  \n",
    "\n",
    "$$\\mu_{i}^{model}(z_{i};\\Omega_{m},w_{0}) \\propto 5log_{10}(\\frac{c(1+z)}{h_{0}})\\int_{0}^{z}\\frac{dz'}{E(z')}$$\n",
    "\n",
    "\n",
    "$$E(z) = \\sqrt{\\Omega_{m} (1+z)^{3} + (1-\\Omega_{m})e^{3\\int_{0}^{z} dln(1+z')[1+w(z')]}}$$\n",
    "\n",
    "This model is used to estimate the posterior distributions of matter density $\\Omega_{m}$ and the dark energy equation of state $w_{0}$.\n",
    "\n",
    "The goal is to show how BOLFI provides useful tools to investigate on the amount of information preserved by the summary statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import numpy as np\n",
    "import scipy.integrate\n",
    "import scipy.stats as sps\n",
    "from scipy.stats import skewnorm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "from statistics import median\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of the Forward Model (or simulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The astroabc package is coded for Python 2.6. In order to use elfi, we need to provide the forward model in Python 3.5. \n",
    "\n",
    "Respect to the original implementation, 1 small modification have been made:\n",
    "1. rather than calling a 2-dim vector for the parameters (i.e. pars[0],pars[1]), we defined param1 and param2.\n",
    "\n",
    "This is done in the following chunks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fitres(fname):\n",
    "                dtype=[('z',np.float32),('mu',np.float32),('mu_err',np.float32)]\n",
    "                data=np.loadtxt(fname,skiprows = 15,dtype =dtype, usecols=(34,48,50))\n",
    "                return data\n",
    "\n",
    "def bin_data(z,mu,err,Nbins=10):\n",
    "    binw = (z.max()-z.min())/Nbins\n",
    "    #print binw\n",
    "    zbins = np.arange(z.min(),z.max(),binw)\n",
    "    mu_in_bin=[];err_in_bin=[]\n",
    "    avmu_bin=[] ; averr_bin=[]\n",
    "    for i in range(Nbins):\n",
    "        mu_in_bin.append([]); err_in_bin.append([])\n",
    "    for i,m in enumerate(mu):\n",
    "        for j in range(Nbins): \n",
    "            if z[i] >=z.min()+ j*binw and z[i] < z.min() + (j+1)*binw:\n",
    "                mu_in_bin[j].append(m) ; err_in_bin[j].append(err[i])\n",
    "    for i in range(Nbins):\n",
    "        if mu_in_bin[i]:\n",
    "            avmu_bin.append(np.mean(mu_in_bin[i]))\n",
    "        else: avmu_bin.append(0)\n",
    "        if err_in_bin[i]:\n",
    "            averr_bin.append(np.mean(err_in_bin[i]))\n",
    "        else: averr_bin.append(0)\n",
    "    return  zbins, avmu_bin,averr_bin,mu_in_bin,mu_in_bin\n",
    "\n",
    "def read_data():\n",
    "    data = read_fitres(\"example_data_file.txt\")\n",
    "\n",
    "    #Keep data points with z>0.5\n",
    "    z_new = data['z'][0]\n",
    "    mu_new = data['mu'][0]\n",
    "    err_new = data['mu_err'][0]\n",
    "\n",
    "    for i in range(1,345):\n",
    "        if data['z'][i] >= 0.5:\n",
    "            z_new = np.append(z_new,data['z'][i])\n",
    "            mu_new = np.append(mu_new,data['mu'][i])\n",
    "        err_new = np.append(err_new,data['mu_err'][i])\n",
    "\n",
    "    #bin this data\n",
    "    zbins,avmu_bin,averr_bin,mu_in_bin_new,mu_in_bin_new = bin_data(z_new,mu_new,err_new,Nbins=20)\n",
    "    return zbins,avmu_bin,averr_bin,mu_in_bin_new,mu_in_bin_new\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_km_per_s = 299792.458\n",
    "\n",
    "class DistanceCalc(object):\n",
    "    def __init__(self,om,ok,ol,wmodel,de_params,h0):\n",
    "        '''\n",
    "        om = omega_matter\n",
    "        ok = omega curvature\n",
    "        ol = omega lambda\n",
    "        wmodel= -1 for LCDM(w0=-1), 0 for (w0,wa) parametrisation, 1 for w0,wa,ap parametrization, 2 for early dark energy\n",
    "        de_params = -1 (if wmodel=-1), =[w0,wa] (if wmodel==0 )\n",
    "        h0 = hubble constant e.g. 0.7\n",
    "        '''\n",
    "        self.om=om\n",
    "        self.ol=ol\n",
    "        self.ok=ok\n",
    "        if self.om + self.ol ==1.: self.is_flat = True\n",
    "        self.wmodel=wmodel\n",
    "        self.de_params=de_params\n",
    "        self.h0=h0\n",
    "        self.d_h =  c_km_per_s/(100.) #Mpc/h\n",
    "\n",
    "    def wfunc(self,a):\n",
    "        if self.wmodel == -1:\n",
    "            w0 = self.de_params\n",
    "            return w0\n",
    "        elif self.wmodel == 0: # e.g. Linder 2003\n",
    "            w0,wa=self.de_params\n",
    "            return w0 + (1.0-a)*wa\n",
    "        elif self.wmodel == 1: # e.g Huterer & Turner 2001\n",
    "            w0,wa,ap=self.de_params\n",
    "            return w0 + (ap-a)*wa\n",
    "        elif self.wmodel ==2: # Wetterich 2004\n",
    "            w0,ode_e = self.de_params\n",
    "            b = -3.*(  w0/( np.log((1.-ode_e)/ode_e) + np.log((1.-self.om)/self.om)  ))\n",
    "            return w0/(1.0 - b*(np.log(a)))\n",
    "            \n",
    "\n",
    "    def w_integrand(self,a):\n",
    "        return (1.+ self.wfunc(a))/a\n",
    "\n",
    "    def w_int(self,z):\n",
    "        a=1./(1.+z)\n",
    "        return 3.0*scipy.integrate.quad(self.w_integrand,a,1.0,epsrel=1e-6,limit=50)[0]\n",
    "\n",
    "    def e_z_inverse(self,z):\n",
    "        if self.wmodel == -1:\n",
    "            return 1./(np.sqrt(self.om*(1+z)**3 + self.ok*(1+z)**2 + self.ol))\n",
    "        else:\n",
    "            return 1./(np.sqrt(self.om*(1+z)**3 + self.ok*(1+z)**2 + self.ol*np.exp(self.w_int(z))))\n",
    "\n",
    "    def d_c(self,z):\n",
    "        return self.d_h*scipy.integrate.quad(self.e_z_inverse,0.0,z,epsrel=1e-6,limit=50)[0]\n",
    "\n",
    "\n",
    "    def d_m(self,z):\n",
    "        '''returns los comoving distance in Mpc/h '''\n",
    "       \treturn self.d_c(z)\n",
    "\n",
    "    def hubble(self,z):\n",
    "        return 100.*self.h0*1./self.e_z_inverse(z)\n",
    "\n",
    "    def d_l(self,z):\n",
    "        '''luminosity dist in Mpc '''\n",
    "        return (1.+z)*self.d_m(z)/self.h0\n",
    "\n",
    "    def d_a(self,z):\n",
    "        '''Ang diameter distance in Mpc'''\n",
    "        return self.d_m(z)/(1.+z)/self.h0\n",
    "\n",
    "    def mu(self,z):\n",
    "        'distance modulus'''\n",
    "        return 5.*np.log10(self.d_l(z)*1.E6/10.) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the forward model.  This must be able to simulate the data at every point in parameter space.  At each $z_{i}$ the simulation uses $\\mu_{model}(z_{i};\\Omega_{m},w_{0})$ given by\n",
    "$$\\mu_{i}^{model}(z_{i};\\Omega_{m},w_{0}) \\propto 5log_{10}(\\frac{c(1+z)}{h_{0}})\\int_{0}^{z}\\frac{dz'}{E(z')}$$\n",
    "\n",
    "to produce a value of distance modulus.  To account for noise in the data we then add a number randomly drawn from a skewed normal distribution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(param1,param2, batch_size=1, random_state=None): #param = [om, w0] \n",
    "    if param1 < 0.0 or param1 > 1.0:\n",
    "        return [None]*len(zbins)\n",
    "    else:\n",
    "        model_1_class = DistanceCalc(param1,0,1-param1,0,[param2,0],0.7)  #om,ok,ol,wmodel,de_params,h0\n",
    "        data_abc = np.zeros(len(zbins))\n",
    "        for i in range(len(zbins)):\n",
    "                data_abc[i] = model_1_class.mu(zbins[i]) + skewnorm.rvs(a, loc=e, scale=w, size=1)\n",
    "        return data_abc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to provide a dataset.  The aim is to generate values of the distance modulus, $\\mu_{i}$, with fixed \"true\" parameters $\\Omega_{m}$ and $w_{0}$\n",
    "\n",
    "$$\\Omega_{m} = 0.3$$\n",
    "$$w_{0} = -1.0$$\n",
    "\n",
    "SNANA is used to generate ~400 supernova light curves which are then fit with the SALT-II light curve fitter. The  data span the redshift interval $z \\in [0.5,1.0]$ and are binned into 20 redshift bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zbins,avmu_bin,averr_bin,mu_in_bin_new,mu_in_bin_new = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding noise to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add artificial noise to the data we use a skewed normal distribution.  The standard normal distribution has a probability distribution function given by\n",
    "\n",
    "$$ \\phi(x) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x^{2}}{2}}$$\n",
    "\n",
    "and a cumulative distribution function: \n",
    "\n",
    "$$\\Phi(x) = \\frac{1}{2} [1 + erf(\\frac{x}{\\sqrt{2}})] $$\n",
    "\n",
    "The skewed normal distribution $f(x)$ with parameter $\\alpha$ is given by \n",
    "\n",
    "$$f(x) = 2\\phi(x)\\Phi(\\alpha x)$$\n",
    "\n",
    "Using this probability distribution function, we can draw a random sample from the skewed normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = -0.1 #location\n",
    "w = 0.3 #scale\n",
    "a = 5.0 #skew\n",
    "\n",
    "plt.figure(figsize=(17,8))\n",
    "plt.hist(skewnorm.rvs(a, loc=e, scale=w, size=10000),normed=True,bins=20,color='#593686')\n",
    "plt.title(\"Distribution of a random sample\",fontsize=17);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this distribution, the noisy data is generated.  At each $z_{i}$ a random number is drawn from the above distribution and added to $\\mu_{i}$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros(len(zbins)) \n",
    "\n",
    "for i in range(len(zbins)):\n",
    "    data[i] = avmu_bin[i] + skewnorm.rvs(a, loc=e, scale=w, size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A comparison of the data before and after noise is added is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,8))\n",
    "plt.errorbar(zbins,avmu_bin,averr_bin,marker=\"o\",linestyle=\"None\",label=\"without noise\",color='#593686')\n",
    "plt.scatter(zbins,data,color='r',label=\"with noise\")\n",
    "plt.legend(loc=\"upper left\",prop={'size':17});\n",
    "plt.xlabel(\"$z$\",fontsize=20)\n",
    "plt.ylabel(\"$\\mu(z)$\",fontsize=20)\n",
    "plt.title(\"Data before and after noise is added\",fontsize=17);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the non-Gaussian distribution of the data at each $z_{i}$, we focus on the data at $z_{1}=0.5$.  The distribution of a large random sample at this redshift is shown below.  Each value in this sample is generated by adding a randomly drawn number from the skewed normal distribution to $\\mu_{1}$.  The value of $\\mu_{1}$ before noise is added is shown in red. As we can see the data is now a skewed distribution around the expected mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0\n",
    "distribution = np.zeros(10000)\n",
    "\n",
    "for j in range(10000):\n",
    "    distribution[j] = avmu_bin[z] + skewnorm.rvs(a, loc=e, scale=w, size=1)\n",
    "\n",
    "plt.figure(figsize=(17,8))\n",
    "plt.title(\"Distribution of the data at redshift z=0.5\",fontsize=17);\n",
    "plt.hist(distribution,bins=20,color='#593686',normed=True)\n",
    "plt.plot((avmu_bin[z], avmu_bin[z]), (0, 2.5), 'r-', label=\"True $\\mu$ at $z = 0.5$\");\n",
    "plt.legend(prop={'size':16});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###call of the forward model\n",
    "model(0.7,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###data used by Jennings et al.\n",
    "data = np.load('dataSupernorva.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###data simulated\n",
    "data = np.loadtxt(fname = \"data_moduli.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of the quantities to run BOLFI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior distributions of $\\Omega_{m}$ and $w_{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prior distributions of $\\Omega_{m}$ and $w_{0}$ are chosen as follows:\n",
    "* $\\Omega_{m}$: we use a Beta distribution.\n",
    "* $w_{0}$: we use a normal distribution.\n",
    "\n",
    "Note that because of the constraint on the forward model, on $\\Omega_{m} \\in (0,1)$, rather than using a Normal distribution (Jennings et al. 2016) we used a Beta Distribution. This is done for not leading to errors when calling BOLFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p1 = elfi.Prior('normal', 0.3, 0.1)\n",
    "#p1 = elfi.Prior('truncnorm', 0, 1)\n",
    "p1 = elfi.Prior('beta',3,3)\n",
    "p2 = elfi.Prior('normal', -0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=elfi.tools.vectorize(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the metric $\\rho$ defined by Jennings et al. 2016 is:\n",
    "$$\\rho(\\mu,\\mu_{sim}(z)) = \\sum_{i} \\frac{(\\mu_{i} - \\mu_{sim}(z_{i}))^{2}}{2 \\sigma_{i}^{2}}$$\n",
    "where $\\sigma_{i}$ is the error on the data point $\\mu_{i}$.\n",
    "\n",
    "We do not consider the denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dist(b,a):\n",
    "        #return np.array([np.sqrt(np.sum((a-b)**2/(2*np.array(averr_bin)**2)))])\n",
    "        return np.array([np.sum(((a-b)/averr_bin)**2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dist(elfi.Simulator.generate(Y),elfi.Simulator.generate(Y))\n",
    "#my_dist(data,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With BOLFI, other several distance metrics could be selected (look at scipy.distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = elfi.Distance(my_dist, Y)\n",
    "\n",
    "elfi.Simulator.generate(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_d = elfi.Operation(np.log, d)\n",
    "elfi.Simulator.generate(log_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOLFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolfi = elfi.BOLFI(log_d, batch_size=1, initial_evidence=500, update_interval=1,\n",
    "                   bounds={'p1':(0, 1), 'p2':(-3, 0)}, acq_noise_var=[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time post = bolfi.fit(n_evidence=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolfi.target_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolfi.plot_state();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolfi.plot_state()\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(-3, 0)\n",
    "for idx, ax in enumerate(plt.gcf().axes):\n",
    "    #ax.add_artist(plt.Circle((0,0), 47.9, color='k', fill=False, linestyle='--'))\n",
    "    ax.axvline(0.3, color='red', linestyle='--')\n",
    "    ax.axhline(-1, color='red', linestyle='--')\n",
    "    if idx == 1:\n",
    "        ax.set_visible(False)\n",
    "plt.savefig('target_surface_GP.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolfi.plot_discrepancy();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the Metropolis-Hastings: remember to perform the thinning! (Done in R)\n",
    "n_samples=10000\n",
    "n_chains=4\n",
    "%time result_BOLFI = bolfi.sample(n_samples, n_chains=n_chains, algorithm='metropolis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOLFI RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_BOLFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_BOLFI.plot_traces();\n",
    "#plt.savefig('traceplotsM-H.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_BOLFI.plot_pairs()\n",
    "#plt.savefig('pairsM-H.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sb.jointplot(x=\"p1\", y=\"p2\", ylim=(-2,-0.25), data=result_BOLFI.samples, kind=\"kde\")\n",
    "\n",
    "f.ax_marg_x.axvspan(left_x, right_x, color='blue', alpha=0.15)  #, linestyle='-')\n",
    "f.ax_marg_y.axhspan(left_y, right_y, color='blue', alpha=0.15)\n",
    "\n",
    "f.ax_marg_x.axvspan(mean(result_BOLFI.samples['p1'])-np.sqrt(np.var(result_BOLFI.samples_array, axis=0))[0],mean(result_BOLFI.samples['p1'])+np.sqrt(np.var(result_BOLFI.samples_array, axis=0))[0], color='yellow',alpha=0.15)\n",
    "f.ax_marg_y.axhspan(mean(result_BOLFI.samples['p2'])-np.sqrt(np.var(result_BOLFI.samples_array, axis=0))[1],mean(result_BOLFI.samples['p2'])+np.sqrt(np.var(result_BOLFI.samples_array, axis=0))[1], color='yellow',alpha=0.15)\n",
    "\n",
    "\n",
    "f.ax_marg_x.axvline(0.3, color='red', linestyle='--')\n",
    "f.ax_marg_y.axhline(-1, color='red', linestyle='--')\n",
    "f.ax_joint.axvline(0.3, color='red', linestyle='--')\n",
    "f.ax_joint.axhline(-1, color='red', linestyle='--', label='Truth')\n",
    "f.set_axis_labels(r'$\\Omega_m$', r'$\\omega_0$')\n",
    "f.ax_joint.plot(result_BOLFI.sample_means['p1'], result_BOLFI.sample_means['p2'], 'gD',label='BOLFI mean')\n",
    "f.ax_joint.plot(0.3,-1.03, 'bo',label='CSL, G=1')\n",
    "#f.ax_joint.plot(mode(result_BOLFI.samples['p1']), mode(result_BOLFI.samples['p2']), 'yX', label='BOLFI mode')\n",
    "#f.ax_joint.plot(median(result_BOLFI.samples['p1']), median(result_BOLFI.samples['p2']), 'co', label='BOLFI median')\n",
    "f.ax_joint.plot(0.297,-1.112, 'yX', label='ABC-SMC Jennings')\n",
    "f.ax_joint.legend(loc='upper right', frameon=True) #ncol=2)\n",
    "f.savefig('contour_posterior_figure.png', bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"BOLFI_output_p1\",result_BOLFI.samples['p1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"BOLFI_output_p2\",result_BOLFI.samples['p2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_BOLFI.sample_means_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.var(result_BOLFI.samples_array, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
